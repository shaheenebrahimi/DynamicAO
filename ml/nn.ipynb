{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple neural net to represent sphere on plane ambient occlusion texture\n",
    "<br/>Inputs: u, v\n",
    "<br/>Output: occlusion factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data \n",
    "# img = imageio.imread('../resources/textures/sphereTex.png')\n",
    "# img = img[:, :, 0] # convert to grayscale\n",
    "# rows = len(img) # rows\n",
    "# cols = len(img[0]) # cols\n",
    "\n",
    "# read data\n",
    "# data = []\n",
    "# with open(\"out.txt\", \"r\") as text_file:\n",
    "#     line = text_file.read()\n",
    "#     data = line.split('\\n')[:-1]\n",
    "#     data = [ list(map(float, x.split(','))) for x in data ]\n",
    "# data = np.array(data)\n",
    "\n",
    "# # split data\n",
    "# np.random.shuffle(data)\n",
    "# partition = int(0.8 * len(data))\n",
    "# X_train = data[:partition, :-1]\n",
    "# y_train = data[:partition, -1] / 255.0\n",
    "# X_test = data[partition:, :-1] \n",
    "# y_test = data[partition:, -1] / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\shaheenebrahimi\\AppData\\Local\\Microsoft\\WindowsApps\\python3.11.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/shaheenebrahimi/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data = []\n",
    "with open(\"../resources/occlusion/data.txt\", \"r\") as text_file:\n",
    "    line = text_file.read()\n",
    "    data = line.split('\\n')[:-1]\n",
    "    data = [ list(map(float, x.split(','))) for x in data ]\n",
    "data = np.array(data)\n",
    "\n",
    "# split data\n",
    "np.random.shuffle(data)\n",
    "partition = int(0.8 * len(data))\n",
    "X_train = data[:partition, :-1]\n",
    "y_train = data[:partition, -1]\n",
    "X_test = data[partition:, :-1] \n",
    "y_test = data[partition:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, input_shape=(2,), activation='tanh'), # hidden\n",
    "    keras.layers.Dense(512, activation='tanh'), # hidden\n",
    "    keras.layers.Dense(1) # output\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\", loss=keras.losses.MeanSquaredError(), metrics=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "300/300 [==============================] - 1s 1ms/step - loss: 0.0645 - mse: 0.0645\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0278 - mse: 0.0278\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0260 - mse: 0.0260\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0251 - mse: 0.0251\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0118\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 31/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 32/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 33/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 34/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 35/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 36/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 37/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 38/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 39/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 40/40\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0015 - mse: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(X_train, y_train, epochs=40, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               1536      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264705 (1.01 MB)\n",
      "Trainable params: 264705 (1.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 3s 375us/step\n"
     ]
    }
   ],
   "source": [
    "# generate texture using model\n",
    "dim = 512\n",
    "inputs = []\n",
    "for r in range(dim,0,-1):\n",
    "    for c in range(dim):\n",
    "        x = [c/(dim-1), r/(dim-1)]\n",
    "        inputs.append(x)\n",
    "outputs = model.predict(inputs)\n",
    "outputs = [ 255 if y[0] > 1 else 255*y[0] for y in outputs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image\n",
    "img = Image.new('L', (dim,dim))\n",
    "img.putdata(outputs)\n",
    "img.save('nnTexture.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual evaluation\n",
    "wab = model.get_weights()\n",
    "w1 = wab[0]\n",
    "b1 = wab[1]\n",
    "w2 = wab[2]\n",
    "b2 = wab[3]\n",
    "w3 = wab[4]\n",
    "b3 = wab[5]\n",
    "\n",
    "z1 = keras.activations.tanh(np.matmul(np.array([0.5, 0.5]), w1) + b1)\n",
    "z2 = keras.activations.tanh(np.matmul(z1, w2) + b2)\n",
    "z3 = keras.activations.tanh(np.matmul(z2, w3) + b3)\n",
    "res = z3.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.755876855928253"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and biases as buffer\n",
    "output_buf = str(len(model.layers)) + \"\\n\" # layer count\n",
    "\n",
    "for i in range(0, len(wab)-1, 2): # iterate through layers\n",
    "    weights = wab[i]\n",
    "    output_buf += str(weights.shape[0]) + \" \" + str(weights.shape[1]) + \"\\n\" # input size output size\n",
    "    for neuron in weights: # iterate through\n",
    "        for edges in neuron:\n",
    "            output_buf += str(edges) + \" \"\n",
    "    for biases in wab[i+1]:\n",
    "        output_buf += str(biases) + \" \"\n",
    "    output_buf = output_buf[:-1] + \"\\n\" # ignore extraneous space and end line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../resources/evaluators/model.txt\", \"w\") as text_file:\n",
    "    text_file.write(output_buf) # add more digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
